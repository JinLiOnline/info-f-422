{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical foundations of Machine Learning\n",
    "\n",
    "## INFO-F-422 TP: Predictions\n",
    "\n",
    "Yann-Aël Le Borgne, Fabrizio Carcillo and Gianluca Bontempi\n",
    "\n",
    "April 25, 2017\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction: supervised learning\n",
    "\n",
    "\n",
    "A supervised learning problem lets us study phenomena for which we have a variable called **output** and a set of other variables called **inputs** and we would like to predict the output using the input variables. We expect that the input variables can explain the observed results of the output variable. We do not know in advance the analytical relationship $y=f(x)$ which could explain the output $y$ in function of the input $x$, we only have a set of pairs (input, output) (the **learning base**). We would like to build a **model** that is a relation of the type $y=f(x)$ which relates the output $y$ to the input $x$. This could then be used for a **prediction** of the output when obtaining new inputs beyond the learning base.\n",
    "\n",
    "In a first step, we will investigate the possibility to use linear models to model non-linear input-output relations and eventually another highly non-linear model: *neural networks*.\n",
    "\n",
    "In a second step, we will investigate the validation problem: once a model has been generated, we have to ask the question if this model is good, that is if it efficiently can predict output variables for new inputs beyond the learning base. The naïve validation consists of comparing the known outputs from the learning base with the computed outputs for the inputs of this learning base using the generated model. This validation can sometimes yield very bad results in the sense that the model seems to perform much better than it is in reality. This problem is known as **overfitting**, it will be demonstrated with a script.\n",
    "\n",
    "This problem arises because the model has been created using the learning base itself and therefore it is not surprising that its performance is good on this set; \n",
    "or the quality of the prediction's result on the learning base does not necessarily imply a good prediction quality for new inputs beyond the base. Therefore, we have to search for other validation procedures. An interesting method is **cross-validation** which will be demonstrated with a script.\n",
    "\n",
    "\n",
    "Finally, we will be considering a classification problem and show that neural networks, or other types of models (decision trees, SVM, nearest neighbors) can be applied to solve these kinds of problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear models\n",
    "\n",
    "A model is called linear if the dependency between the parameters and the output variable is linear. The relation between the input variables and the output variable does not necessarily have to be linear. \n",
    "\n",
    "### Exercises\n",
    "\n",
    "* Write a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls.pol<-function(X.tr,Y.tr,m,X.ts){}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " that given a training set X.tr and Y.tr builds a polynomial model of degree $m$ by using the function `lm`. The function returns a list of arguments: 'pred' for model predictions for the test data X.ts and 'Remp' for the mean squared errors based on the residuals returned by the `lm` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a training set for the noisy function y=f(x) on [-1;0.5]\n",
    "X.tr<-seq(-1,0.5,by=0.05)\n",
    "Y.tr<-sin(2*pi*X.tr)+rnorm(length(X.tr),sd=0.2)\n",
    "\n",
    "#Create the test set\n",
    "X.ts<-seq(-1,0.5,by=0.01)\n",
    "Y.ts<-sin(2*pi*X.ts)\n",
    "\n",
    "N<-length(X.tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Create a model with increasing complexity using the following training set, and evaluating with the test set. Try orders $m\\in[1,12]$ of polynomial approximations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks\n",
    "\n",
    "The command `nnet` creates a neural network model (non-linear model) for the formula provided as input (parametric identification) by using the input data and then returns the created model. It is necessary to load the package  `nnet`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(nnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the neural model has been created, it can be used for predicting the output for new input data by employing the function `predict` (see scripts). Type `help(nnet)` in R for more details. The parameters $x$ and $y$ correspond to the inputs and the outputs respectively (from the learning base used for creating the model). The other parameters we use are `size` for the number of units in the hidden layer, `maxit` for the maximal number of iterations and `linout` to specify if a neuron's output function is linear or logistic (regression or classification).\n",
    "\n",
    "*  Using the function, training and test sets established in the previous section, build neural networks for different sizes of hidden layers $\\in[1,12]$ with linear output. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max.n.par<-12\n",
    "min.n.par<-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  For how many neurons in the hidden layer do you obtain the best generalization capacity? \n",
    "*  Note that the convergence of a neural network depends on the initialization of the network's weights. What happens if the generator's random number seed is changed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "The K-fold cross-validation provides the possibility to obtain a MSE estimate which is much more realistic than the empirical error on new test data. It is in particular used for detecting overfitting and to choose a model. The following code uses neural networks with different numbers of hidden nodes to model the dependencies between X and Y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "par(mfrow=c(3,4))\n",
    "for (n.par in min.n.par:max.n.par){\n",
    "    model<- nnet(X.tr,Y.tr,\n",
    "                     size=n.par,\n",
    "                     maxit=1000,\n",
    "                     trace=FALSE,linout=TRUE)\n",
    "                     \n",
    "    Remp=mean((model$fitted.values-Y.tr)^2)\n",
    "    Y.hat<- predict(model,array(X.ts,c(length(X.ts),1)))\n",
    "    Rtest<-mean((Y.hat-Y.ts)^2)\n",
    "    \n",
    "       plot(X.tr,Y.tr,\n",
    "         col=\"red\",\n",
    "         main=paste(\"# hidden units nnet=\",n.par, \"\\n Empirical error=\", round(Remp,digits=4),\"\\n Test error=\",round(Rtest,digits=4) ),\n",
    "         xlab=\"X\",\n",
    "         ylab=\"Y\")\n",
    "    lines(X.ts,Y.ts,col=\"black\")\n",
    "    lines(X.ts,Y.hat,col=\"green\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises \n",
    "\n",
    "Adapt the previous code to carry out a 10-fold cross validation using the same parameters to fit the neural network. Which model seems to be the best one using cross-validation? Does this match the error obtained on the test set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "We will demonstrate the resolution of a classification problem using neural networks. In a classification problem the output variable is discrete and not necessarily ordered (i.e. the type of animal, the shape of a character). If the output variable is binary (for example TRUE/FALSE), the problem can be solved by replacing the two possibilities by $0$ and $1$ and then using a prediction model based on least squares. \n",
    "\n",
    "### Exercises\n",
    "\n",
    "Using the data set `BreastCancer.Rdata` which consists of nine input variables characterizing medical measures for 683 patients. The output variable  is $1$ if the person was healed and $0$ otherwise. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rm(list=ls())\n",
    "library(nnet)\n",
    "set.seed(0)\n",
    "\n",
    "#Load Breast Cancer data set \n",
    "load(\"BreastCancer.Rdata\")\n",
    "\n",
    "#make it balanced w.r.t. labels\n",
    "I1<-which(Y==1)\n",
    "I0<-which(Y==0)\n",
    "subI0<-sample(I0,length(I1))\n",
    "\n",
    "X2<-rbind(X[subI0,],X[I1,])\n",
    "Y2<-c(Y[subI0],Y[I1])\n",
    "\n",
    "size<-length(Y2)\n",
    "index<-sample(1:size)\n",
    "\n",
    "X<-X2[index,]\n",
    "Y<-Y2[index]\n",
    "\n",
    "X<-data.frame(X)\n",
    "\n",
    "#Create a training and a test set\n",
    "i.tr<-sample(1:size,round(size/3))\n",
    "i.ts<-setdiff(1:size,i.tr)\n",
    "X.tr<-X[i.tr,]\n",
    "Y.tr<-Y[i.tr]\n",
    "X.ts<-X[i.ts,]\n",
    "Y.ts<-Y[i.ts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Build a neural network model on the training data of size 10 with a maximum number of iterations 1000 and logistic output. Use this model to predict the outcome of the test data. Compute the mean classification error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Perform this analysis in cross-validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  The specification of a prediction model is often very similar from one package to another. Install the packages `tree`, `lazy` and `e1071` which implement decision tree, nearest neighbor and SVM models. Create the same classification analysis using linear models `lm`, decision trees `tree`, SVM models `svm` and lazy learning `lazy`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
